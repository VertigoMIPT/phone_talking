{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phone talking detection neural network.\n",
    "Naive approach.\n",
    "Pipeline:\n",
    "1) Detect face on image\n",
    "2) Crop Region of Interest (ROI) - face + const (80x80 pix)\n",
    "3) Classify whether person talking on the phone or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D,ZeroPadding2D\n",
    "from keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad,Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from six.moves import cPickle as pickle\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.backend as K\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D,ZeroPadding2D\n",
    "from keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad,Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import itertools\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.layers import Input, Dense, Add, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "        \n",
    "from keras.layers import Input, Dense, Add, Activation, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D,Conv1D, MaxPooling2D\n",
    "\n",
    "from keras.layers import Input, Dense, Add, Activation\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results were achieved using CNN with one Inception block\n",
    "https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 80, 80, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 80, 80, 64)   640         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 40, 40, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 40, 40, 64)   4160        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 40, 40, 64)   4160        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 40, 40, 64)   4160        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 40, 40, 64)   36928       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 40, 40, 64)   102464      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 20, 20, 64)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 20, 20, 64)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 20, 20, 64)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 20, 20, 64)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 20, 20, 256)  0           max_pooling2d_7[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 102400)       0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          13107328    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            129         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,276,481\n",
      "Trainable params: 13,276,481\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Y = np.load('/home/aevdakimov/Загрузки/Telegram Desktop/y.pickle', allow_pickle=True)\n",
    "X = np.load('/home/aevdakimov/Загрузки/Telegram Desktop/X.pickle', allow_pickle=True)\n",
    "\n",
    "\n",
    "X_open = np.load('/home/aevdakimov/Загрузки/Telegram Desktop/X_open.pickle', allow_pickle = True)\n",
    "Y_open = np.load('/home/aevdakimov/Загрузки/Telegram Desktop/y_open.pickle', allow_pickle = True)\n",
    "\n",
    "\n",
    "Y_train = np.hstack((np.array(Y_open),(np.array(Y))))\n",
    "X_train = np.vstack((np.array(X_open),(np.array(X))))\n",
    "\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train)\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "#X_train = X_train/255        \n",
    "\n",
    "\n",
    "img_shape = 80\n",
    "num_channels = 1\n",
    "\n",
    "input_img = Input(shape=(img_shape, img_shape, num_channels))\n",
    "\n",
    "\n",
    "X = input_img\n",
    "\n",
    "X = Conv2D(64, (3,3), padding='same', activation='relu')(X)\n",
    "X = MaxPooling2D(pool_size=(2, 2))(X)\n",
    "\n",
    "way_0 = MaxPooling2D(pool_size=(2, 2))(X)\n",
    "\n",
    "way_1 = Conv2D(64, (1,1), padding='same', activation='relu')(X)\n",
    "way_1 = MaxPooling2D(pool_size=(2, 2))(way_1)\n",
    "\n",
    "way_2 = Conv2D(64, (1,1), padding='same', activation='relu')(X)\n",
    "way_3 = Conv2D(64, (3,3), padding='same', activation='relu')(way_2)\n",
    "way_3 = MaxPooling2D(pool_size=(2, 2))(way_3)\n",
    "\n",
    "\n",
    "way_4 = Conv2D(64, (1,1), padding='same', activation='relu')(X)\n",
    "way_5 = Conv2D(64, (5,5), padding='same', activation='relu')(way_4)\n",
    "way_5 = MaxPooling2D(pool_size=(2, 2))(way_5)\n",
    "\n",
    "\n",
    "output = keras.layers.concatenate([way_0, way_1, way_3, way_5], axis = 3)\n",
    "\n",
    "\n",
    "X = Flatten()(output)\n",
    "\n",
    "\n",
    "X = Dense(128, activation='relu')(X)\n",
    "X = Dropout(0.4)(X)\n",
    "\n",
    "X = Dense(128, activation='relu')(X)\n",
    "X = Dropout(0.4)(X)\n",
    "\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(X)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=input_img, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model = Model(inputs=input_img, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#model.fit(X_train, Y_train, batch_size=128,epochs=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained model\n",
    "\n",
    " model = load_model('/Users/user/Downloads/model_inception_v4_aug_64_64_64_64_64_64.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function detects face on the image, passes through NN,\n",
    "# picture rectangle around ROI if predict is higher than threshold \n",
    "detector = MTCNN()\n",
    "\n",
    "def phone(image, model, detector):\n",
    "\n",
    "    crop_path = '/Users/user/Data_science/skytrack/imgs'\n",
    "\n",
    "    pred = 0\n",
    "\n",
    "    result = detector.detect_faces(image) # detecting face\n",
    "    const = 50\n",
    "    try:\n",
    "        bounding_box = result[0]['box'] \n",
    "    \n",
    "        x1 = bounding_box[0] - const\n",
    "        x2 = (bounding_box[0] + bounding_box[2]) + const\n",
    "        y1 = bounding_box[1]-const\n",
    "        y2 = bounding_box[1]+bounding_box[3]+const\n",
    "        \n",
    "        crop_img = image[y1:y2, x1:x2] # cropping img\n",
    "        \n",
    "        tmp = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "        tmp = tmp/255.\n",
    "        tmp = cv2.resize(tmp, (80, 80)) # getting required ROI\n",
    "        \n",
    "        pred = model.predict(np.reshape(np.array(tmp),(1,80,80,1)))\n",
    "        if pred >= 0.95: # threshold\n",
    "            image = cv2.rectangle(image, (x1,y1), (x2,y2), (255,0,0), 3)\n",
    "        print(pred)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5853238]]\n",
      "[[0.3947083]]\n",
      "[[0.13922094]]\n",
      "[[0.13631833]]\n",
      "[[0.1115536]]\n",
      "[[0.12363242]]\n",
      "[[0.13036759]]\n",
      "[[0.1153552]]\n",
      "[[0.29043055]]\n",
      "[[0.11144801]]\n",
      "[[0.17165452]]\n",
      "[[0.1997334]]\n",
      "[[0.12335743]]\n",
      "[[0.13799615]]\n",
      "[[0.1989433]]\n",
      "[[0.72685194]]\n",
      "[[0.35198867]]\n",
      "[[0.08310848]]\n",
      "[[0.85032237]]\n",
      "[[0.68617177]]\n",
      "[[0.10072633]]\n",
      "[[0.4864713]]\n",
      "[[0.3156617]]\n",
      "[[0.10090802]]\n",
      "[[0.1129461]]\n",
      "[[0.3445109]]\n",
      "[[0.8752569]]\n",
      "[[0.4927609]]\n",
      "[[0.3490645]]\n",
      "[[0.33495468]]\n",
      "[[0.06610416]]\n",
      "[[0.09733833]]\n",
      "[[0.10565314]]\n",
      "[[0.10392562]]\n",
      "[[0.62708074]]\n",
      "[[0.8360292]]\n",
      "[[0.9630065]]\n",
      "[[0.9944436]]\n",
      "[[0.99733716]]\n",
      "[[0.9982151]]\n",
      "[[0.99950683]]\n",
      "[[0.99940073]]\n",
      "[[0.9996164]]\n",
      "[[0.99948007]]\n",
      "[[0.99958724]]\n",
      "[[0.99936885]]\n",
      "[[0.9996439]]\n",
      "[[0.9988992]]\n",
      "[[0.99899405]]\n",
      "[[0.9991443]]\n",
      "[[0.96220577]]\n",
      "[[0.30073088]]\n",
      "[[0.09198131]]\n",
      "[[0.20460051]]\n",
      "[[0.30817315]]\n",
      "[[0.31082642]]\n",
      "[[0.31985247]]\n",
      "[[0.43161705]]\n",
      "[[0.27241582]]\n",
      "[[0.24023423]]\n",
      "[[0.8135438]]\n",
      "[[0.88844085]]\n",
      "[[0.7066775]]\n",
      "[[0.96450174]]\n",
      "[[0.747187]]\n",
      "[[0.9866253]]\n",
      "[[0.9913747]]\n",
      "[[0.99527127]]\n",
      "[[0.9435688]]\n",
      "[[0.76596457]]\n",
      "[[0.9675277]]\n",
      "[[0.9845576]]\n",
      "[[0.99240667]]\n",
      "[[0.9904225]]\n",
      "[[0.99703383]]\n",
      "[[0.9864932]]\n",
      "[[0.9836705]]\n",
      "[[0.9921302]]\n",
      "[[0.9914555]]\n",
      "[[0.96941423]]\n",
      "[[0.38943446]]\n",
      "[[0.3290804]]\n",
      "[[0.2763308]]\n",
      "[[0.06205909]]\n",
      "[[0.19142355]]\n",
      "[[0.20990686]]\n",
      "[[0.14870745]]\n",
      "[[0.06665057]]\n",
      "[[0.18664342]]\n",
      "[[0.06874876]]\n",
      "[[0.13238493]]\n",
      "[[0.06897777]]\n",
      "[[0.11592134]]\n",
      "[[0.18900932]]\n",
      "[[0.3236913]]\n",
      "[[0.15634076]]\n",
      "[[0.18133263]]\n",
      "[[0.41670772]]\n",
      "[[0.61552423]]\n",
      "[[0.6938847]]\n",
      "[[0.8162421]]\n",
      "[[0.70966756]]\n",
      "[[0.68454313]]\n",
      "[[0.04622693]]\n",
      "[[0.21718799]]\n",
      "[[0.07797255]]\n",
      "[[0.08671938]]\n",
      "[[0.02415535]]\n",
      "[[0.03030753]]\n",
      "[[0.0790332]]\n",
      "[[0.06652711]]\n",
      "[[0.05990755]]\n",
      "[[0.17608126]]\n",
      "[[0.14261146]]\n",
      "[[0.06061368]]\n",
      "[[0.04223773]]\n",
      "[[0.12722069]]\n",
      "[[0.12034833]]\n",
      "[[0.09399534]]\n",
      "[[0.5515182]]\n",
      "[[0.1382267]]\n",
      "[[0.14022839]]\n"
     ]
    }
   ],
   "source": [
    "# Launcher \n",
    "import numpy as np \n",
    "import cv2   \n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "  \n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG') \n",
    "out = cv2.VideoWriter('output1.avi', fourcc, 30.0, (640, 480)) \n",
    "\n",
    "identifiers = {}\n",
    " \n",
    "while(True): \n",
    "    ret, frame = cap.read()      \n",
    "    image = frame    \n",
    "    image = phone(image, model, detector)\n",
    "    \n",
    "    out.write(image)       \n",
    "    cv2.imshow('phone', image) \n",
    "     \n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'): \n",
    "        break\n",
    "          \n",
    "cap.release() \n",
    "  \n",
    "out.release()  \n",
    "   \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Center_2M",
   "language": "python",
   "name": "center_2m"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
